% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluate_ti_method.R
\name{evaluate_ti_method}
\alias{evaluate_ti_method}
\title{Running an evaluation of a method on a set of datasets with a set of parameters}
\usage{
evaluate_ti_method(datasets, method, parameters, metrics, output_model = TRUE,
  mc_cores = 1, verbose = FALSE)
}
\arguments{
\item{datasets}{The datasets on which to evaluate.}

\item{method}{The method to evaluate.}

\item{parameters}{The parameters to evaluate with.}

\item{metrics}{which metrics to evaluate:
\enumerate{
  \item Spearman correlation of geodesic distances: \code{"correlation"}
  \item Edge flip score: \code{"edge_flip"}
  \item RF MSE: \code{"rf_mse"}, \code{"rf_rsq"}
  \item Similarity in feature importance: \code{"featureimp_cor"}
  \item Custom metric function. Format: \code{function(dataset, model) { 1 }}
}}

\item{output_model}{Whether or not the model will be outputted.}

\item{mc_cores}{The number of cores to use, allowing to parallellise the different datasets}

\item{verbose}{Whether or not to print extra information output.}
}
\description{
Running an evaluation of a method on a set of datasets with a set of parameters
}
