% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/benchmark_suite.R
\name{benchmark_suite_submit}
\alias{benchmark_suite_submit}
\title{A benchmark suite with which to run all the methods on the different tasks}
\usage{
benchmark_suite_submit(tasks, task_group, task_fold, out_dir, timeout = 60 *
  nrow(tasks), methods = get_descriptions(as_tibble = TRUE),
  metrics = c("auc_R_nx", "robbie_network_score"), num_cores = 4,
  memory = "20G", num_iterations = 20, num_init_params = 100,
  num_repeats = 1)
}
\arguments{
\item{tasks}{A tibble of tasks.}

\item{task_group}{A grouping vector for the different tasks.}

\item{task_fold}{A fold index vector for the different tasks.}

\item{out_dir}{The folder in which to output intermediate and final results.}

\item{timeout}{The number of seconds 1 method has to solve each of the tasks before a timeout is generated.}

\item{methods}{A tibble of TI methods.}

\item{metrics}{Which metrics to use;
see \code{\link{calculate_metrics}} for a list of which metrics are available.}

\item{num_cores}{How many cores to use per mlrMBO process.}

\item{num_iterations}{The number of iterations to run.}

\item{num_init_params}{The number of initial parameters to evaluate.}

\item{num_repeats}{The number of times to repeat the mlr process, for each group and each fold.}
}
\description{
A benchmark suite with which to run all the methods on the different tasks
}
